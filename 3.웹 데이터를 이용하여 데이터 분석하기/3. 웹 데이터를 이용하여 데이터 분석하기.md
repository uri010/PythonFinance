## Python Finance

### 3. 웹 데이터를 이용하여 데이터 분석하기 (2022.01.05)

> python의 requests 모듈을 이용하여 웹에서 데이터를 불러와 분석하는 것을 배움



#### requests 모듈

- requests는 파이썬으로 HTTP 호출하는 프로그램을 작성할 때 가장 많이 사용되는 라이브러리

##### API

- 직관적인 API 제공
- HTTP 요청 방식에 따라 해당하는 이름의 함수를 사용
  - GET 방식 : `requests.get()`
  - POST 방식 : `requests.post()`
  - PUT 방식 : `requests.put()`
  - DELETE 방식 : `requests.delete()`

##### 응답 상태

- 온라인 서비스를 HTTP로 호출하면 상태 코드를 응답받음
- 상태코드는 응답 객체의 `status_code`속성을 통해 얻을 수 있음

##### 응답 전문

- 요청이 정상적으로 처리된 경우 응답전문(response body/payload)에 요청한 데이터가 닮겨져 옴
- 읽어들이는 방식
  - `content` 속성 - 바이너리 원문
  - `text` 속성 - UTF-8로 인코딩된 문자열
  - `json()` 함수 - 응답 데이터가 JSON 포멧일 경우 dictionary 객체

##### 응답 헤더

- 응답에 대한 메타 데이터를 담고 있음
- `header` 속성을 통해 dictionary 형태로 얻을 수 있음

##### 요청 쿼리

- GET 방식으로 HTTP 요청을 할 때는 query string을 통해 응답 받을 데이터를 필터링함
-  `params` 옵션을 사용해 쿼리 스크링을 dictionary 형태로 넘길 수 있음

##### 요청 전문

- POST나 PUT 방식으로 HTTP 요청시 보통 request body/payload에 데이터를 담아 보냄
- `data`옵션을 사용하면 HTML양식(form) 포멧의 데이터를 전송할 수 있음
  - 이 때 `Content-Type` 요청 헤더는 `application/x-www-form-unlencoded`로 자동 설정
- `json `옵션을 사용하면 REST API로 JSON 포멧의 데이터를 전송할 수 있음
  - 이 때 `Content-Type` 요청 헤더는 `application/json`으로 자동 설정

##### 요청 헤더

- `header`옵션을 사용해 요청 헤더 직접 설정 가능
- 인증 토큰을 보낼 때 유용



#### BeautifulSoup 모듈

##### Soup 클래스화

- requests 통신으로 가져온 HTML 코드를 `Soup`로 만듦

##### Direct tag 참조

- `title`, `head`, `body`와 같은 최상단 태그를 가져올 수 있음
- 무언가를 찾을 때 하위 태그로 한 단계 이동 후 찾는 게 효율적

##### find

- 제일 가까운 태크 하나를 찾음

##### find_all

- 여러 개의 태그를 가져올 수 있음
- 태그 목록이 반환되어 for문을 사용하여 가공할 수 있음

##### 클래스 ( CLASS ) 

- 기본적으로 `find`의 두번째 파라미터는 찾고자 하는 클래스를 나타냄
- `find (태그, CLASS 명)`

##### 아이디 ( ID ) 

- `find( 태그, id = id 명) `

##### 그 외 FIND

- `find_parents()` and `find_parent()`
- `find_next_sibilings()` and `find_next_sibiling()`
- `find_previous_sibilings()` and `find_previous_sibiling()`
- `find_all_next()` and `find_next()`
- `find_all_previous()` and `find_previous()`



##### requests 모듈과 bs4 모듈 예시 코드

```python
#requests 모듈은 브라우저의 서버로 요청을 보낼수 있게함
#bs4 모듈은 requests로 가져온 HTML 코드의 태그에 접근할 수 있게 함
import requests
import bs4

naver_url='https://www.naver.com/'
naver_response=requests.get(naver_url) # 주소창에 url입력 후 서버로 요청받아서 응답 받는 과정을 구현
# naver_response는 응답객체

naver_bs=bs4.BeautifulSoup(naver_response.text,'lxml') # 뷰티풀스프형 데이터로 변환/ 옵션은 lxml (markdown언어로 속도가 빨라서 주로 사용)
#뷰티풀스프는 html코드의 성질을 이용하여 이용자가 원하는 정보를 찾아줌

#하지만 태그만으로 정보를 가져오기엔 태그도 많으며 같은 태그를 가지는 정보도 많음
#그러므로 속성값과 같은 것이 필요 ex)class
result=naver_bs.find('div',class_ = 'logo_area') # class값이 'logo_area'인 데이터만 가져옴 
print(result.text)
```



#### 구현하기

```python
#데이터 구하기도 문제->전처리
#웹크롤링 or 웹 스크래핑

#requests 모듈은 브라우저의 서버로 요청을 보낼수 있게함
#bs4 모듈은 requests로 가져온 HTML 코드의 태그에 접근할 수 있게 함
import requests
import bs4
import pandas as pd

fs_url='https://comp.fnguide.com/SVO2/ASP/SVD_Finance.asp?pGB=1&gicode=A005380&cID=&MenuYn=Y&ReportGB=D&NewMenuID=103&stkGb=701' # 연간 테이블을 가져오기 위해 ReportGB를 D로 설정한 주소를 가져옴
fs_page=requests.get(fs_url) # fs_url의 정보를 서버에게 요청해 응답받아 fs_page에 저장
fs_tables=pd.read_html(fs_page.text) # html 코드에서 필요한 데이터만 찾아내어 데이터프레임으로 형성

#포괄손익계산서
temp_df=fs_tables[0]
temp_df=temp_df.set_index('IFRS(연결)') # 'IFRS(연결)'이 해당하는 열을 index로 설정
temp_df=temp_df[['2018/12','2019/12','2020/12','2021/09']] # 해당 열만 가져옴
temp_df=temp_df.loc[['매출액','영업이익','당기순이익']] # loc로 원하는 행을 추출

#재무상태표
temp_df2=fs_tables[2]
temp_df2=temp_df2.set_index('IFRS(연결)')
temp_df2=temp_df2.loc[['자산','부채','자본']]

#현금흐름표
temp_df3=fs_tables[4]
temp_df3=temp_df3.set_index('IFRS(연결)')
temp_df3=temp_df3.loc[['영업활동으로인한현금흐름']]

fs_df=pd.concat([temp_df,temp_df2,temp_df3]) # 표 붙이기 - 열이나 행이 동일해야 합쳐질 수 있음


#위의 코드를 함수화 시키기
def make_fs_dataframe(firm_code): # 기업코드에 따라 다른 데이터프레임 생성
    fs_url='https://comp.fnguide.com/SVO2/ASP/SVD_Finance.asp?pGB=1&cID=&MenuYn=Y&ReportGB=D&NewMenuID=103&stkGb=701&gicode='+firm_code # 주소에서 &끼리 연결된 값은 순서가 바뀌어도 상관없음
    fs_page=requests.get(fs_url)

    fs_tables=pd.read_html(fs_page.text)

    temp_df=fs_tables[0]
    temp_df=temp_df.set_index(temp_df.columns[0]) # IFRS뿐만아니라 GAAP도 있기때문에 첫번째 column에 어떤 값이 와도 수용 가능
    temp_df=temp_df[temp_df.columns[:4]] # 날짜가 바뀔수도 있음
    temp_df=temp_df.loc[['매출액','영업이익','당기순이익']]

    temp_df2=fs_tables[2]
    temp_df2=temp_df2.set_index('IFRS(연결)')
    temp_df2=temp_df2.loc[['자산','부채','자본']]


    temp_df3=fs_tables[4]
    temp_df3=temp_df3.set_index('IFRS(연결)')
    temp_df3=temp_df3.loc[['영업활동으로인한현금흐름']]
    fs_df=pd.concat([temp_df,temp_df2,temp_df3])

    return fs_df

print(make_fs_dataframe('A005380'))

# 데이터 병합에 대해 생각해보자
# 회사코드가 단독으로 인덱스나 칼럼에 들어가는 것이 비교하기에 좋다.

# 2018/12칼럼 하나만 길게 변경시키기

code = 'A005930'
fs_df=make_fs_dataframe(code)
temp_df=pd.DataFrame({code:fs_df['2018/12']})
temp_df=temp_df.T # 전치
temp_df.columns=[['2018/12']*len(fs_df),temp_df.columns]

# 전부 바꾸기
code = 'A005930'
fs_df=make_fs_dataframe(code)

for num,col in enumerate(fs_df.columns): # num은 0부터 시작해서 +1씩 늘어남, col은 fs_df.columns의 0번째 data부터 n번째 data까지

    temp_df=pd.DataFrame({code:fs_df[col]})
    temp_df=temp_df.T
    temp_df.columns=[['2018/12']*len(fs_df),temp_df.columns]
    if num==0:
        total_df=temp_df
    else:
        total_df=pd.merge(total_df,temp_df,how='outer',left_index=True,right_index=True) # outer : 합집합 / merge : 표 옆으로 붙이기

#함수화
def change_df(firm_code,dataframe):
    for num,col in enumerate(fs_df.columns):

        temp_df=pd.DataFrame({firm_code:dataframe[col]})
        temp_df=temp_df.T
        temp_df.columns=[[col]*len(dataframe),temp_df.columns]
        if num==0:
            total_df=temp_df
        else:
            total_df=pd.merge(total_df,temp_df,how='outer',left_index=True,right_index=True)
    return total_df

#지금까지의 함수를 이용하면 웹에서 데이터를 가져와 데이터프레임을 만들고
#원하는 형태로 바꾸어 회사코드가 인덱스인 데이터프레임을 갖게된다.

firmcode_list=['A005930','A005380','A035420']
for num,code in enumerate(firmcode_list):
    fs_df=make_fs_dataframe(code)
    fs_df_changed=change_df(code,fs_df) # chage_df함수를 통해 해당 코드를 가진 기업의 데이터를 배열로 정렬
    if num==0:
        total_fs=fs_df_changed 
    else:
        total_fs=pd.concat([total_fs,fs_df_changed]) # concat함수로 배열로 정렬한 데이터를 밑에 붙이기
total_fs
```

